---
fontsize: 12pt
output: 
  pdf_document:
    includes:  
      in_header: myheader.tex
    latex_engine: xelatex
    number_sections: yes
    toc: yes
    toc_depth: 2
mainfont: Arial
header-includes:
    - \usepackage[font={small,it}, labelfont={bf}]{caption}
    - \usepackage{fancyhdr}
    - \usepackage{lipsum}
    - \pagestyle{fancy}
    - \fancyhead[LO,RE]{}
    - \fancyhead[R]{BUAN 6359.002 | Group 7}
    
---


```{r loadPackages, echo = FALSE, warning=FALSE, message=FALSE}

if(!require("pacman")) install.packages("pacman")
pacman::p_load(esquisse, forecast, tidyverse, gplots, GGally, gganimate, dplyr, tidyr, e1071, caTools, class, mlbench, BiocManager,
               mosaic, scales, mosaic, mapproj, mlbench, data.table, datasets, rpartScore, MASS, caret, mapproj, purrr, kableExtra, magrittr,
               nnet, rpart, rpart.plot, stratifyR, DMwR, RColorBrewer, randomForest, leaps, gains, rpartScore,
               class, caTools, DMwR)
```

\newpage



# Executive Summary


The increased number of vehicles on the roads and express highways has led to an increase in the number of accidents in the whole of the United States. Saving human life is important. But, a road accident is often accompanied by infrastructure loss, traffic delays, and management of resources to clear the accident spot. This project was built on the business scenario to facilitate City’s Transportation Management Center (TMC) to predict the traffic delay level, post road accidents, and effectively deploy their resources. A countrywide car accident database from February 2016 to June 2020 (Moosavi, Samavatian, Parthasarathy and Ramnath, 2020) has been used as the data source. Several multivariate statistical techniques have been utilized to classify the impact of the accident on traffic delays. Predictive models were developed using ordinal logistic regression, binomial logistic regression, k-nearest neighbor, discriminant analysis, decision tree and random forest algorithms. K-Nearest Neighbor algorithm is considered as the best model for this data with high sensitivity and specificity. A conscious effort has been made in building a model with the input variables, whose data will be available when an accident is reported at TMC. 



\newpage


# Introduction


United States is one the countries with busiest traffic conditions. “The level of traffic is one of the reasons leading to more traffic accidents: In 2018, there were some 12 million vehicles involved in crashes in the United States”(Wagner, 2020). Recent statistical projection of National Highway Traffic Safety Administration estimated that 36,120 people have died in motor vehicle traffic accidents in 2019. Although, total fatal crashes have declined by 1.2 percent from 2018, Federal Highway Administration reports the total vehicle miles traveled (VMT) in 2019 is increased by about 28.8 billion miles or about 0.2 percent increase from 2018 (National Center for Statistics and Analysis, 2020). This shows that people are traveling more on the roadways. One of the major impacts of higher VMT is Congestion.

In literature, congestion is believed to have very mixed effects on roadway accidents. Many studies have found a strong positive relationship between congestion and total accidents (Woo, 1957; Head, 1959). However, some researchers have found that there is U shaped function relationship between the two variables implying higher accidents at low or high congestion levels (Zhou & Sisiopiku, 1997; Martin, 2002).  It has also been found that fatalities are more often at median level traffic compared to high or low traffic conditions. This implies that congestion can be viewed as a potential safety bearer but a nightmare for traffic management authorities. There is no clear consensus on the effects of congestion on vehicle crashes or vice versa  (Retallack & Ostendorf, 2019). Both congestion and crashes not only incurs social cost, but also infrastructure and economic loses. 

In 2010, the total economic cost of road accidents in the United States was estimated to be $242 billion. Traffic congestion caused post road accident, including travel delay and excess fuel consumption accounted for nearly $28 billion (Blincoe, Miller, Zaloshnja, & Lawrence, 2015).  Minor Traffic Incidents and accidents with injuries but no fatalities have an expected event duration of up to 2 hours to clear traffic; Major Truck Accidents and Multivehicle Crashes has an event duration of 2 to 24 hours (Wallace, ITS Professional Capacity Building Program, n.d.). Hence, there is a need to study the traffic delays as a function of roadway and weather characteristics at the accident spots. 

$~$

## Business Scenario

Traffic Management Centers (TMC) serves as a control center to manage urban roads and highways. It is responsible to monitor traffic signals, intersections, and roads and actively strategize to alleviate congestion. They also coordinate with the local agencies during special events, emergencies, accidents, and regular day to day operations. Operators at TMC monitor the roadways through closed-circuit television (CCTV) system to inform the authorities aboutany problems. These TMC’s also have representatives from law enforcement, emergency management services(EMS), and local transit agencies for easy cooperation among themselves to efficiently manage any untoward situations.

This project would be essential for a City’s Transportation Management Center (TMC) to analyze and predict the traffic delay level post accident to efficiently manage their resources. The project would also help the state-licensed Emergency Medical Services (EMS) Dispatch centers to recognize the requirement of airlift to save the life.



\newpage

## Data Description

**US Accidents** is countrywide traffic accident dataset constituting all the accidents in 49 states of the US, from February 2016 to June 2020(Moosavi, Samavatian, Parthasarathy and Ramnath, 2020). There are nearly 3.5 million road accident records with City and state wise information about TMC code, accident severity, time when impact of accident on traffic was dismissed, GPS coordinates, length of road affected by accident, weather conditions, and nearby points of interest. The description of the variables can be found in the appendix 1.

```{r readData , echo = FALSE}
## Load data set as a data table
USacc <- data.table(fread("US_Accidents_June20.csv"))
```

$~$


**Dataset Acknowledgments:**

Moosavi, Sobhan, Mohammad Hossein Samavatian, Srinivasan Parthasarathy, and Rajiv Ramnath. “A Countrywide Traffic Accident Dataset.”, arXiv preprint arXiv:1906.05409 (2019).

Moosavi, Sobhan, Mohammad Hossein Samavatian, Srinivasan Parthasarathy, Radu Teodorescu, and Rajiv Ramnath. “Accident Risk Prediction based on Heterogeneous Sparse Data: New Dataset and Insights.” In proceedings of the 27th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, ACM, 2019


$~$

## Objective 

This study focuses on two objective:

1.	Perform Hypothesis testing on initial assumptions about the variables in the dataset

2.	Build a predictive model using machine learning algorithms that can be used by TMC centers to effectively manage their resources 



$~$


## Prelimnary Assumptions

Following are the preliminary assumptions made in this study:

* Traffic delay level is correlated with the location of the accidents.

* Most of the accidents happen in adverse weather conditions and the traffic delay level is correlated with weather. 

* Traffic delay level is high during AM (7:00 - 9:00) and PM (16:00 - 18:00) peak period.

* A typical weekday and weekend have a different share of traffic delay level 3 accidents.

* Temperature, Humidity and Precipitation are significant predictors of traffic delay level.



\newpage


# Data Preprocessing

The US accidents data set has a large number of incomplete and missing information. 
Data cleaning is done in order to address the anomalies.


## Formatting

```{r Time format, echo = FALSE, warning = FALSE, message = FALSE}

## Setting Time 
USacc$ST <- as.POSIXct(USacc$Start_Time, format = "%Y-%m-%d %H:%M:%S")
USacc$ET <- as.POSIXct(USacc$End_Time, format = "%Y-%m-%d %H:%M:%S")
USacc$Weather_Times <- as.POSIXct(USacc$Weather_Timestamp, format = "%Y-%m-%d %H:%M:%S")

# Renaming Distance column
names(USacc)[names(USacc)=="Distance(mi)"] <- "Distance"


#Removing columns
USacc <- USacc[,!c('Start_Time', 'End_Time', 'Weather_Timestamp', 'Country', 'Wind_Chill(F)', 'End_Lat', 'End_Lng', 'Civil_Twilight', 'Nautical_Twilight', 'Astronomical_Twilight')]

```

Since the data is collected for various sources, the data format is inconsistent. For the analysis, the date and time formats for Start_Time, End_Time and Weather_Timestamp have been standardized as ‘YYYY-MM-DD HH:mm:ss’. 


## Adding a calculated field

```{r cal fields, echo = FALSE, warning = FALSE, message = FALSE}

# Duration in min 
USacc$Traffic_Dur_min <- (as.numeric(USacc$ET) - as.numeric(USacc$ST))/60
USacc <- USacc[USacc$Traffic_Dur_min > 0 & USacc$Traffic_Dur_min < 360,]

# Adding Day of the week
USacc$Day <- weekdays(as.Date(USacc$ST))

```

The severity level in this data indicates the impact of an accident on traffic and not the severity of the actual accident. To avoid the confusion, severity level will be referred as **traffic delay level**. The accidents in this dataset were reported by three different sources. In order to compare the classification of the traffic delay levels among different sources, it is essential to have the duration of the traffic post-accident. A new calculated field **Traffic_Duration_min** (difference between End time when the impact of accident on traffic flow was dismissed and the accident start time) has been introduced indicating the duration of traffic post-accident in minutes. For this analysis, the Traffic duration up to six hours (360 min) has been considered. 


To understand the pattern of accidents according to the time of day, day of the week and month,**STHR**, **Day** and **Month** columns have been introduced. "STHR" captures the start hour of the accident, "Day" represents the day of the week and "Month" as a categorical variable depicting the month of the accident.


## Missing values

Table 1 shows the percentage of null records of all the variables.

```{r missing values, echo = FALSE, warning=FALSE}

## NA summary
missvaltotal <- data.frame(value = colSums(is.na(USacc)))
#missvaltotal$names <- rownames(missvaltotal)
missvaltotal$Proportion_Missing <- (missvaltotal$value/nrow(USacc)*100)

missval.var <- missvaltotal[missvaltotal$value > 0, ]


knitr::kable(missval.var,
             caption = "Proportion of missing values in the data set",
             digits = 2)

```

It was observed that End_Lat and End_long variables had nearly 70.5% of the missing values. 

```{r Missing values Texas, echo = FALSE, warning = FALSE, message = FALSE}

### Since we will be considering only texas moving ahead, data manipulation is done only for texas.

#Texas data
Texas <- USacc %>%
  filter(State == "TX") 


## Adding Month
Texas$Month <- month(Texas$ST)


#Removing NA for Precipitation
Filter1 <- Texas[!is.na(Texas$`Precipitation(in)`),]
MonthAvgPrep <- Filter1 %>% group_by(Month) %>% summarise(AvgPrep = mean(`Precipitation(in)`))

Texas <- merge(Texas,MonthAvgPrep)
Texas$Precipitation <- Texas$`Precipitation(in)`

Texas$AvgPrep[!is.na(Texas$Precipitation)] <- Texas$Precipitation[!is.na(Texas$Precipitation)]

Texas$Precipitation <- Texas$AvgPrep
Texas <- Texas[,-c("AvgPrep","Precipitation(in)")]



#Removing NA for temperature
Filter2 <- Texas[!is.na(Texas$`Temperature(F)`),]
MonthAvgTemp <- Filter2 %>% group_by(Month) %>% summarise(AvgTemp = mean(`Temperature(F)`))

Texas <- merge(Texas,MonthAvgTemp)
Texas$Temperature <- Texas$`Temperature(F)`

Texas$AvgTemp[!is.na(Texas$Temperature)] <- Texas$Temperature[!is.na(Texas$Temperature)]

Texas$Temperature <- Texas$AvgTemp
Texas <- Texas[,-c("AvgTemp","Temperature(F)")]



#Removing NA for humidity
Filter3 <- Texas[!is.na(Texas$`Humidity(%)`),]
MonthAvgHum <- Filter3 %>% group_by(Month) %>% summarise(AvgHum = mean(`Humidity(%)`))

Texas <- merge(Texas,MonthAvgHum)
Texas$Humidity <- Texas$`Humidity(%)`

Texas$AvgHum[!is.na(Texas$Humidity)] <- Texas$Humidity[!is.na(Texas$Humidity)]

Texas$Humidity <- Texas$AvgHum
Texas <- Texas[,-c("AvgHum","Humidity(%)")]



#Removing NA for Pressure
Filter4 <- Texas[!is.na(Texas$`Pressure(in)`),]
MonthAvgPres <- Filter4 %>% group_by(Month) %>% summarise(AvgPres = mean(`Pressure(in)`))

Texas <- merge(Texas,MonthAvgPres)
Texas$Pressure <- Texas$`Pressure(in)`

Texas$AvgPres[!is.na(Texas$Pressure)] <- Texas$Pressure[!is.na(Texas$Pressure)]

Texas$Pressure <- Texas$AvgPres
Texas <- Texas[,-c("AvgPres","Pressure(in)")]



#Removing NA for WindSpeed
Filter5 <- Texas[!is.na(Texas$`Wind_Speed(mph)`),]
MonthAvgws <- Filter5 %>% group_by(Month) %>% summarise(Avgws = mean(`Wind_Speed(mph)`))

Texas <- merge(Texas,MonthAvgws)
Texas$WindSpeed <- Texas$`Wind_Speed(mph)`

Texas$Avgws[!is.na(Texas$WindSpeed)] <- Texas$WindSpeed[!is.na(Texas$WindSpeed)]

Texas$WindSpeed <- Texas$Avgws
Texas <- Texas[,-c("Avgws","Wind_Speed(mph)")]




#Removing NA for Visibility
Filter6 <- Texas[!is.na(Texas$`Visibility(mi)`),]
MonthAvgvis <- Filter6 %>% group_by(Month) %>% summarise(Avgvis = mean(`Visibility(mi)`))

Texas <- merge(Texas,MonthAvgvis)
Texas$Visibility <- Texas$`Visibility(mi)`

Texas$Avgvis[!is.na(Texas$Visibility)] <- Texas$Visibility[!is.na(Texas$Visibility)]

Texas$Visibility <- Texas$Avgvis
Texas <- Texas[,-c("Avgvis","Visibility(mi)")]


# Creating a new file for Texas records
write.csv(Texas, file = "Texas_Final_data.csv")


```

There are missing values in the variables depicting the weather conditions of the accidents, like Temperature, Pressure, Wind speed, Humidity, Precipitation and visibility. These missing values have been replaced with the monthly average value of the respective variables.

$~$

## Dropping the Variables

*	The dataset describes the US accidents. Thus, the country variable that had only single value as ‘US’ has been dropped.

*	The End_Lat and End_long variables are also dropped considering the percent of the missing values in them.

*	The temperature at the time of the accidents is already captured by ‘Temperature(F)’ variable. The ‘Wind_Chill(F)’ has been dropped to reduce redundancy in the data set. 

*	Similarly, the ‘Sunrise_Sunset’ variable captures all the information of ‘Civil_Twilight’, ‘Nautical_Twilight’ and ‘Astronomical_Twilight’. The latter variables have been dropped from the dataset for this analysis.

$~$

## Duplicates and Outliers

```{r Dropping texas, echo = FALSE, warning = FALSE, message = FALSE}

texas <- fread("Texas_Final_data.csv")
texas <- data.table(texas)

#Removing columns
texas <- texas[,!c('Start_Time', 'End_Time', 'Weather_Timestamp', 'Country', 'Wind_Chill(F)', 'End_Lat', 'End_Lng', 'Civil_Twilight', 'Nautical_Twilight', 'Astronomical_Twilight')]


# duplicate records
texas <- texas %>% distinct(Start_Lat,Start_Lng, Weather_Times, .keep_all= TRUE)


# outlier records
# Distance 
texas <- texas[texas$Distance < 20,]

#Precipitation
texas <- texas[texas$Precipitation < 2.5,]

#Temperature
texas <- texas[texas$Temperature > 0 & texas$Temperature < 110,]

#Pressure
texas <- texas[texas$Pressure > 10 ,]

#Windspeed
texas <- texas[texas$WindSpeed < 120 ,]

#Visibility
texas <- texas[texas$Visibility > 0 & texas$Visibility < 15 ,]


# Reformating texas
texas$Day <- as.factor(texas$Day)
texas$ST <- as.POSIXct(texas$ST, format = "%Y-%m-%d %H:%M:%S")
texas$ET <- as.POSIXct(texas$ET, format = "%Y-%m-%d %H:%M:%S")

```

*	Some records had nearly erroneous weather condition values that were identified as outliers in the dataset. These records are deleted for the analysis. 

*	Duplicate records were identified and deleted. 

*	Some of the records had discrepancies in their start and end time. These records have also been dropped from this analysis.


\newpage

# Data Manipulation

## Sources and their traffic delay level

US accidents data set has accidents reported from three different sources – MapQuest, Bing and MapQuest-Bing. 
From the graph below, the data set has nearly 77.2% total reported incidents by MapQuest followed by Bing which accounts for 21%. The third category MapQuest-Bing contributes less than 2% of all the records with the US accidents dataset.


$~$

```{r source pie chart, echo = FALSE, warning=FALSE, message= FALSE ,fig.height = 3.5, fig.cap = "*Sources of the accident report*"}

# Extracting proportions
Source_prop <- USacc %>%
            group_by(Source) %>%
            summarise(count = n()) %>%
            mutate(Sourceprop = round(count / sum(count) * 100, 1)) %>%
            arrange(desc(Source)) %>%
            mutate(lab.ypos = cumsum(Sourceprop) - 0.5*Sourceprop)

# colour scheme
mycol <- c("#00009a","#44d3ff","#e1f8ff")

# Donut chart
ggplot(Source_prop, aes(x = 2, y = Sourceprop, fill = Source)) +
  geom_bar(stat = "identity", color = "white") +
  coord_polar(theta = "y", start = 0)+
  geom_text(aes(y = lab.ypos, label = paste0(Sourceprop,'%')), color = "White")+
  scale_fill_manual(values = mycol) +
  theme_void()+
  xlim(0.5, 2.5)


```

$~$

These sources report traffic accidents in four traffic delay levels 1, 2, 3 and 4. Traffic delay 1 indicates the least impact on traffic (i.e. short delay as a result of the accident) and 4 indicates a significant impact on traffic (i.e. long delay).

```{r Severity souces , echo = FALSE, warning = FALSE, message = FALSE}

Sev_Source <- USacc %>% 
    group_by(Source, Severity) %>% 
    summarise(value = round(mean(Traffic_Dur_min),2)) %>% 
    spread(Severity, value)

knitr::kable(Sev_Source,
             caption = "Average duration of the accident impact on traffic(in minutes)- Source vs Traffic delay categorization",
             digits = 2)
```

$~$

The table 2 shows the discrepancy in traffic delay level categorization for duration of accident impact on traffic (in minutes) reported by different sources. There is a need to reclassify the traffic delay levels before proceeding with the analysis.




## Weather Conditions 

US accidents data set has Weather_Condition variable to depicting the conditions at the time of accidents. There are more than 20 categories defined due to the reporting of various sources. 

For this analysis, the weather conditions have been redefined as  ‘Clear’, ‘Partly Cloudy’, ‘Cloudy’, ‘Rain’, ‘Thunderstorm’, ‘Fog’ ,‘Other’.

$~$

```{r weather new, echo = FALSE, warning = FALSE, message= FALSE}

WeatherCondition <- read.csv('UniqueWeatherConditions.csv')

texas <- merge(texas, WeatherCondition, by.x = 'Weather_Condition', by.y = 'UniqueWeatherCondition', all.x = TRUE)

texas$Weather_New[is.na(texas$Weather_New)] <- "Clear"

# Converting into Factor
texas$Weather_New <- as.factor(texas$Weather_New)

#Removing source column
texas <- texas[,!c('Weather_Condition')]

```


$~$

$~$


# Exploratory Data Analysis

## State wise Statistics

Among the 49 states in the US, the greatest number of accidents has occurred in the state of California (800K+) followed by Texas (330K+) and Florida(250K+).
California, Texas and Florida have nearly 40% of the total number of accidents in the US from February 2016 to June 2020. 

$~$

```{r state stats, echo = FALSE, warning = FALSE, message= FALSE, fig.cap = "*State wide accident statistics*"}

options(scipen = 999)

df <- read.csv("StateData.csv")
df$NAME <- toupper(df$NAME)

map.df <- USacc %>% group_by(State) %>% summarise(Count = n())
df <-  merge(df, map.df, by.x = "STUSPS", by.y="State")

#Map
states_map <- map_data("state")

states_map$region <- toupper(states_map$region)
states_map <- merge(states_map, df, by.x = "region", by.y = "NAME")

# Create the map
ggplot(states_map, aes(long, lat, group = group))+
  geom_polygon(aes(fill = Count), color = "white")+
  scale_fill_gradient(high = "#00009a",low = "#e1f8ff", breaks = c(200000, 600000), labels = c("200k", "600k")) +
  theme( axis.title = element_blank(),
                  axis.text = element_blank(),
                  axis.ticks = element_blank(),
                  axis.line = element_blank(),
                  panel.grid.major = element_blank(), 
                panel.grid.minor = element_blank(),
                panel.background = element_blank(),
                legend.position = "top")


```

$~$


```{r top city level, echo = FALSE, warning = FALSE, message= FALSE, fig.height = 3.5 , fig.cap = " *Number of accidents at City level* "}

options(scipen = 999)

City <- USacc %>% 
    group_by(State , City) %>%
    summarise(count = n()) %>%
    arrange(desc(count)) %>%
    head(n = 10) 

City <- data.table(City)

ggplot(City, aes(x = reorder(City, -count), y = count))+
            geom_bar(stat='identity', fill = "#e1f8ff") +
            geom_bar(data = subset(City, State == "TX"),fill = "#00009a", stat="identity")+
            geom_text(aes(label = count), position = position_dodge(width=0.9), vjust=-0.25, size = 2) +
            theme(axis.title.x = element_blank(),
                  axis.title.y = element_blank(),
                  axis.text.y = element_blank(),
                  axis.ticks.y = element_blank(),
                  axis.line.y = element_blank(),
                  axis.text.x = element_text(angle = 90),
                panel.background = element_blank())
 

```


Houston, Dallas and Austin in Texas state are among top five cities with highest number of accidents records. Thus, further analysis will be focused on Accidents within Texas state from the US Accidents data set.

$~$


## Texas Statistics

It is alarming to know that Texas state has not had a day without one traffic accidents since 2000 (KRW Attorneys at Law, n.d.). 

```{r texas acc, echo = FALSE, warning = FALSE, message= FALSE, fig.cap= " *Accidents in Texas* ", fig.width= 5.5}

options(scipen = 999)

#Map
states_map <- map_data("state")
texas_map <- data.table(states_map[states_map$region == "texas",])

texas_map$region <- toupper(texas_map$region)
texas_map <- merge(texas_map, df, by.x = "region", by.y = "NAME")

# Create the map
ggplot(texas_map, aes(long, lat))+
          geom_polygon(fill = "gray88") +
          geom_point(data = texas, aes(x = Start_Lng, y = Start_Lat), color= "#00009a", size = 0.5, alpha=0.5)+
          theme(axis.title.x = element_blank(),
                  axis.title.y = element_blank(),
                  axis.text = element_blank(),
                  axis.ticks = element_blank(),
                  axis.line = element_blank(),
                panel.grid.major = element_blank(), 
                panel.grid.minor = element_blank(),
                panel.background = element_blank(),
                legend.position = "right")


```
 
From figure 4 "Accidents in Texas", it can be inferred that the majority of the accidents in Texas state are along the Interstate Highways and major cities of El Paso, San Antonio, Austin, Houston, and Dallas.

$~$

$~$

The original data had discrepancy in traffic delay level categorization. For this analysis the traffic delay levels have been re-classified. The user defined variable Traffic_Dur_min was considered as the determining factor. Since the first quartile and the median was 30min, it was ideal to re-categorize into just three levels of severity. The new traffic delay levels were defined based on values of 33rd and 66th percentiles.


```{r redefinind new traffic delay levels texas, echo = FALSE, warning = FALSE, message= FALSE}


#Re-clasify traffic delay level
texas$Delay_new <- as.integer(texas$Delay_new)
texas$Delay_new <- 0

texas$Delay_new[texas$Traffic_Dur_min <= 30] <- 1
texas$Delay_new[texas$Traffic_Dur_min > 30 & texas$Traffic_Dur_min <= 45] <- 2
texas$Delay_new[texas$Traffic_Dur_min > 45] <- 3


texas$Delay_new <- as.factor(texas$Delay_new)

# traffic delay level re-classification levels
new_sev.lvl <- data.table()
new_sev.lvl$`Traffic delay level` <- c("1","2","3")
new_sev.lvl$`Time taken to clear traffic` <- c("Up to 30 min", "30 min – 45 min", "More than 45 min")

knitr::kable(new_sev.lvl,
             caption = "Traffic delay level re-classification")

#Removing original columns
texas <- texas[,!c('Source','Severity')]

#write.csv(texas, file = "Texas_Final_Cleaned_data.csv")
```

$~$

Traffic delay level 1 indicates the least impact on traffic post accident and traffic delay level 3 indicates a significant impact on traffic post road accident.


\newpage

The geographic locations of accidents are overlayed on the texas map to visually analyse the relationship between traffic delay level and their locations.

```{r texas acc with traffic delay levels, echo = FALSE, warning = FALSE, message= FALSE, fig.cap = "*Texas Road Accidents with traffic delay levels*"}


# Create the map
ggplot(texas_map, aes(long, lat))+
  geom_polygon(fill = "gray88") +
  geom_point(data = texas, aes(x = Start_Lng, y = Start_Lat, col = Delay_new),size = 0.5, alpha=0.5)+
  scale_color_manual(values = c("#e1f8ff","#44d3ff","#00009a")) +
  labs(color = "Traffic delay level")+
  theme(axis.title.x = element_blank(),
                  axis.title.y = element_blank(),
                  axis.text = element_blank(),
                  axis.ticks = element_blank(),
                  axis.line = element_blank(),
                panel.grid.major = element_blank(), 
                panel.grid.minor = element_blank(),
                panel.background = element_blank(),
                legend.key = element_blank())


```

As assumed initially, it can be clearly seen that majority of the traffic delay level 3 accidents (traffic clear time more than 45min) are on the highways and toll roads. This also indicates a correlation between location of the accident and the traffic delay level. As expected, the resources of TMC and EMS would take more time to reach on these highways when compared to a location within city limits.

$~$

Frequency of accidents in Texas was plotted against various weather conditions to test the hypothesis that the road accidents are highest in adverse conditions, 

```{r weather new texas, echo = FALSE, warning = FALSE, message= FALSE, fig.cap = " *Number of Accidents in various weather conditions* ", fig.height= 3}

Weather_acc <- texas %>% 
    group_by(Weather_New) %>%
    summarise(count = n()) %>%
    mutate(percent = round(count / sum(count)*100 ,2))

Weather_acc <- data.table(Weather_acc)


ggplot(Weather_acc, aes(x = Weather_New, y = count, fill = Weather_New)) +
         geom_bar(stat = "identity") +
            geom_text(aes(label = paste0(percent,"%")), position = position_dodge(width=0.9), vjust=-0.25, size = 2)+
        scale_fill_brewer(palette = "Blues") +
            theme(axis.title.x = element_blank(),
                  axis.title.y = element_blank(),
                  axis.text.y = element_blank(),
                  axis.ticks.y = element_blank(),
                  axis.line.y = element_blank(),
                  legend.position = "none",
                  panel.grid.major = element_blank(), 
                panel.grid.minor = element_blank(),
                panel.background = element_blank())


```

$~$

In US, 24% of the total road accidents are weather related. (Pisano, Goodwin, & Rossetti, 2008). This holds true even in case of Texas, where 22.63% of accidents are in adverse weather conditions.

The highest number of accidents have occurred during the clear weather condition. It is surprising to note that 77.37% of the total accidents are in clear, partly cloudy and cloudy weather conditions. This could possibly mean that people avoid driving or drive more carefully during adverse weather conditions like rain, thunderstorm etc.  

$~$

$~$

To test the Null Hypothesis that the traffic delay post the accident is dependent on the weather condition, Pearson's chi-squared test is carried out. The goodness of the fit of the data, as well as the check for dependency of the two categorical variables can be understood.

$~$

```{r chi test weather v/s delay, echo = FALSE, warning = FALSE, message= FALSE}

Chi_weather.severity <- table(texas$Weather_New,texas$Delay_new)

Chi.Weather = chisq.test(Chi_weather.severity )
Chi.Weather

# expected
Chi.Weather$expected

#Observed
Chi.Weather$observed


```

$~$

Since the associated p-value is less than significance level of 5% , we do not reject the null hypothesis. In a study conducted in 2009, the effect of weather conditions on the daily traffic intensities were examined. It tested if all the weather condition impacted in a similar way or not. The conclusions indicated that extreme weathers such as snowfall, rainfall, and increased wind speed had a diminishing impact on the traffic intensity, while increased temperatures on open and sunny days had a positive impact on the traffic intensity measured over a specific segment of the road (Cools, Moons, & Wets, 2009). It can be concluded that the traffic delay level is dependent on the weather conditions.  


There is a significant difference between the observed values and expected values across the different traffic delay levels. The contingency table demonstrates the distribution of traffic delay levels across different Weather Conditions. As seen from figure 6, most of the accidents takes place in clear weather conditions. 

$~$


The distribution of accidents by time period is considered to test the assumption that traffic delay level is high during AM (7:00 - 9:00) and PM (16:00 - 18:00) peak periods within a day.

$~$

```{r acc by hr, echo = FALSE, warning = FALSE, message= FALSE, fig.height = 3, fig.cap = "*Texas Road Accidents by time of day*"}

texas$STHR <-  hour(texas$ST)

# Severity1
sev1 <- texas[ which(texas$Delay_new == 1), ]

tod1 <- sev1 %>% 
  group_by(STHR) %>% 
  summarise(count = n()) %>% 
  mutate(Prop = count/sum(count)*100)


# Severity2
sev2 <- texas[ which(texas$Delay_new == 2), ]

tod2 <- sev2 %>% 
  group_by(STHR) %>% 
  summarise(count = n()) %>% 
  mutate(Prop = count/sum(count)*100)


# Severity3
sev3 <- texas[ which(texas$Delay_new == 3), ]

tod3 <- sev3 %>% 
  group_by(STHR) %>% 
  summarise(count = n()) %>% 
  mutate(Prop = count/sum(count)*100)

# merging all three
tod <- merge(tod1, tod2, by = "STHR")
tod <- merge(tod, tod3, by = "STHR")

#creating the plot
ggplot(tod, aes(x = STHR)) + 
  geom_line(aes(y = Prop.x, color = "1")) +
  geom_line(aes(y = Prop.y, color = "2")) +
  geom_line(aes(y = Prop, color = "3"))+
  scale_x_continuous(breaks = seq(min(tod1$STHR), max(tod1$STHR), by = 1)) + 
  scale_color_manual(values = c("#c7f1ff","#44d3ff","#00009a")) +
  xlab ("Time of Day") +
  ylab ("Percentage share of the Accidents") +
  ylim(0,15) +
  labs(color = "Traffic delay level") +
  theme(panel.grid.major = element_blank(), 
                panel.grid.minor = element_blank(),
                panel.background = element_blank(),
        legend.position = "top",
        legend.key = element_blank())

```

$~$

The percentage of the accidents is highest for all three traffic delay levels during AM peak period. This can be related to the fact that a greater number of vehicles are on road for either going to workplace or dropping kids to school. Traffic delay level 2 is highest during AM peak which indicates that the traffic post accidents mostly clears up within 30 min to 45 min. 

A second peak can be observed in traffic delay level 1 and 3 during PM peak (16:00 - 18:00). The traffic delay level 3 around 16:00 hours might be due to trips taken back from school or work and shopping trips.


$~$

$~$


In this dataset, 89.6% of accidents have been reported during a weekday and 10.4% of accidents have been reported on weekends. The bar chart below represents the percentage share of accidents for different severity levels on each day of the week. 

$~$

```{r acc by weekday, echo = FALSE, warning = FALSE, message= FALSE, fig.height= 3.2, fig.cap = " *Texas Road Accidents by Weekdays* "}

texas$Day <- weekdays(as.Date(texas$ST))
texas$Day <- factor(texas$Day, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))

Day_acc <- texas %>% 
    group_by(Day, Delay_new) %>%
    summarise(count = n()) %>%
    mutate(percent = round(count / sum(count)*100 ,1))

Day_acc <- data.table(Day_acc)


ggplot(Day_acc, aes(x = Day, y = percent, fill = Delay_new)) +
         geom_bar(stat = "identity", position = "dodge") +
            geom_text(aes(label = paste0(percent,"%")), position = position_dodge(width=0.9), vjust=-0.25, size = 2) +
        scale_fill_manual(values = c("#c7f1ff","#44d3ff","#00009a")) +
        labs(fill = "Traffic delay level") +
            theme(axis.title.x = element_blank(),
                  axis.title.y = element_blank(),
                  axis.text.y = element_blank(),
                  axis.ticks.y = element_blank(),
                  axis.line.y = element_blank(),
                  panel.grid.major = element_blank(), 
                panel.grid.minor = element_blank(),
                panel.background = element_blank(),
                legend.position = "top")
       
```

$~$

As seen from Figure 8, percentage share of traffic delay level 1 and 3 are similar across all the weekdays. However, the traffic delay level 1 is higher on weekends compared to weekdays. Unlike traffic delay 1, the traffic delay 2 has less percentage share on weekends when compared to weekdays. The traffic delay 3 is similar across weekdays and weekends. 

$~$


```{r chi test day v/s delay, echo = FALSE, warning = FALSE, message= FALSE}

Chi_day.severity <- table(texas$Day,texas$Delay_new)

Chi.Day = chisq.test(Chi_day.severity )
Chi.Day 

# expected
Chi.Day$expected

#Observed
Chi.Day$observed


```

$~$

From the contingency table it is observed that the number of accidents happen more on the weekdays than on the weekends. This is possible as the number of vehicles on roads is higher on weekdays compared to weekends.

$~$


Further, the percentage share of delay levels on an average weekday and weekend was analyzed to test the hypothesis that the delay level 3 is different on a typical weekday compared to typical weekend. 

$~$

```{r acc by weekday vs weekend, echo = FALSE, warning = FALSE, message= FALSE, fig.height= 3, fig.width = 5, fig.cap = " *Texas Road Accidents on Weekday v/s weekend* "}

texas$Weekend <- ifelse(texas$Day == "Saturday" | texas$Day == "Sunday", "Weekend", "Weekday")

weekend_acc <- texas %>% 
    group_by(Weekend, Delay_new) %>%
    summarise(count = n()) 

# adding Average count
weekend_acc$avg.count <- ifelse(weekend_acc$Weekend == "Weekday", weekend_acc$count/5, weekend_acc$count/2)

# total count
weekday.sum <- sum(weekend_acc$count[weekend_acc$Weekend == "Weekday"])
weekend.sum <- sum(weekend_acc$count[weekend_acc$Weekend == "Weekend"])

# Percentage
weekend_acc$percent <- ifelse(weekend_acc$Weekend == "Weekday", round(weekend_acc$avg.count/weekday.sum*100 , 1), round(weekend_acc$avg.count/weekend.sum*100 , 1))

weekend_acc <- data.table(weekend_acc)

ggplot(weekend_acc, aes(x = Weekend, y = percent, fill = Delay_new)) +
         geom_bar(stat = "identity", position = "dodge") +
            geom_text(aes(label = paste0(percent,"%")), position = position_dodge(width=0.9), vjust=-0.25, size = 2)+
            scale_fill_manual(values = c("#c7f1ff","#44d3ff","#00009a")) +
            labs(fill = "Traffic delay level") +
            theme(axis.title.x = element_blank(),
                  axis.title.y = element_blank(),
                  axis.text.y = element_blank(),
                  axis.ticks.y = element_blank(),
                  axis.line.y = element_blank(),
                  panel.grid.major = element_blank(), 
                  panel.grid.minor = element_blank(),
                  panel.background = element_blank())
       
```

$~$

The proportion of accidents with traffic delay 3 (more than 45min to clear traffic post-accident) is higher on a typical weekend when compared to weekday. 
Prop test is also conducted to know if proportion of number of traffic delay 3 accidents on weekdays and weekends are statistically differing.

$~$

```{r delay lvl 3 weekday and weekend, echo = FALSE, warning = FALSE, message= FALSE, fig.cap = " *Accidents by Day/Night* "}

texas$Weekend <- as.factor(texas$Weekend)
TableDelayWeekend <- table(texas$Delay_new,texas$Weekend)
TableDelayWeekend

prop.table(TableDelayWeekend)
 
prop.test(TableDelayWeekend[3,2], n = (TableDelayWeekend[3,1] + TableDelayWeekend[3,2]) , p= 0.5, alternative = "two.sided", conf.level = 0.95, correct = FALSE)

```

$~$

The p - value is less than the level of significance 0.05. Therefore, we reject the hypothesis that the proportion of accidents with traffic delay level 3 is equal on weekdays and on weekends. 

The test of proportions as used as the test statistic, to understand if the observed proportion is different from our initial expected proportion.




\newpage

# Empirical Analysis

This project is aimed to facilitate City’s Transportation Management Center (TMC) to predict traffic delay level (categorical data) post road accidents and effectively deploy their resources.

The summary of traffic delay levels showed that nearly 52% of the total observation belonged to traffic delay level 1. To ensures that each delay level within the total accident population receives proper representation within the sample, for this analysis, the observations are classified as train data and test data using a stratified random sample method. The training data consists of 80% of the observations randomly selected from each delay level. The rest 20% of the observations are considered as test and validation data.

```{r train and test, echo = FALSE, warning = FALSE, message= FALSE}

# making the logical vectors with 1 and 0 values
texas[ ,19:31][ texas[ , 19:31 ] == TRUE ] <- 1
texas[ ,19:31][ texas[ , 19:31 ] == FALSE ] <- 0

texas[ ,19:31] <- lapply(texas[ ,19:31], factor)
texas$Weekend <- as.factor(texas$Weekend)
texas$Sunrise_Sunset <- as.factor(texas$Sunrise_Sunset)


Predictors <- texas[,c("V1", "Start_Lat", "Start_Lng", "ST", "Bump", "Crossing", "Give_Way", "Junction",  
                   "No_Exit" , "Railway" , "Roundabout" , "Station" , "Stop" , "Traffic_Calming" , "Traffic_Signal",
                   "Sunrise_Sunset" , "Weather_New" , "Day" ,"Precipitation" , "Temperature" , "WindSpeed" ,
                   "Humidity" , "Pressure" , "STHR" , "Weekend", "Delay_new")]


set.seed(42)
train.data <- Predictors %>% group_by(Delay_new) %>% sample_frac(0.8)
test.data <- anti_join(Predictors, train.data, by = "V1")


```

$~$

## Stepwise regression model

```{r regsubset, echo = FALSE, warning = FALSE, message= FALSE}

search <- regsubsets(Delay_new ~ ., data = train.data, nbest = 1, nvmax = dim(train.data)[2],
                     method = "seqrep")

reg.summary <- summary(search)

```


A conscious effort has been made to build a model with the input variables, whose data will be available at the moment an accident has been reported. The variables manual chosen are "Start_Lat", "Start_Lng", "ST", "Bump", "Crossing", "Give_Way", "Junction",  "No_Exit", "Railway", "Roundabout", "Station", "Stop", "Traffic_Calming", "Traffic_Signal", "Sunrise_Sunset", "Day" , "Weather_New", "Precipitation", "Temperature", "WindSpeed", "Humidity" , "Pressure" , "STHR" (time of day) , "Weekend".

After running the stepwise regression, the model with the highest adjusted R squared was selected as the best model. The detailed results of the stepwise regression can be referred to in the appendix 2. The model 26 has the highest adjusted r square value(0.1746969). The predictor variables used in this model are Start_Lat, Start_Lng, ST, Crossing, Give_Away, Junction, Railway, Roundabout, Station, Stop, Traffic_Signal, Sunrise_Sunset, Precipitation, Temperature, Windspeed, Humidity, Pressure, STHR, and Weekend.

$~$

## Ordinal Multiclass Classification

### Ordinal logistic regression

Since the traffic delay level is ordinal data, Ordinal logistic regression was the first choice to predict an ordinal dependent variable given one or more independent variables. The variables of the best stepwise regression model were used as the predictors for the response variable in the ordinal logistic model.

```{r ordinal reg model, echo = FALSE, warning = FALSE, message= FALSE}

# Training data
polr.LR.ord <- polr(Delay_new ~ Start_Lat + Start_Lng + Crossing + Give_Way + Junction + Railway + Roundabout + Station + Stop + Traffic_Signal +
                      Sunrise_Sunset + Precipitation + Temperature + WindSpeed + Humidity + Pressure + Weekend,
                   data = train.data, Hess = T)

summary(polr.LR.ord)

# Test data
polr.LR.ord.pred <- predict(polr.LR.ord, test.data, type = "class")

# Confusion matrix
confusionMatrix(polr.LR.ord.pred, test.data$Delay_new)

```

$~$

The accuracy of this ordinal logistic model is approximately 59%. But the model was not able to predict class 2 i.e. Delay level 2 records. In the main Texas dataset, Traffic delay level 1 is the dominant class with more than 52% of records. Hence, one of the possible reasons for this model to ignore the delay level 2 prediction was the lack of traffic delay level 2 observations in the training dataset. 


$~$

$~$


### Ordinal logistic regression with SMOTE

To even out the number of records across all three traffic delay levels, oversampling for traffic delay level 2 and 3 observations were carried out using the SMOTE technique for the training data. The SMOTE technique can be applied to only two classes. For this project, this technique was applied to the training dataset of traffic delay levels 2 and 3 only. 

```{r train and test oversample, echo = FALSE, warning = FALSE, message= FALSE}

train.data$Delay_new <- as.numeric(train.data$Delay_new)
train.data <- as.data.table(train.data)

# Only Taking Severity 2 and 3 for oversampling from the train dataset. 
# We would use the test dataset for validation later
texas_2_3 <- train.data[train.data$Delay_new > 1]

texas_2_3$Delay_new <- factor(texas_2_3$Delay_new)

# Taking only the required columns for oversampling to reduce run time
texas_2_3_Var <- texas_2_3[,c('Delay_new','Start_Lat','Start_Lng', 'Bump', 'Crossing',
                             'Give_Way', 'Traffic_Calming', 'Junction','Stop',
                             'Traffic_Signal','Weekend', 'Sunrise_Sunset','Precipitation', 'Temperature','WindSpeed', 'Humidity','Pressure')]


texas_1 <- train.data[train.data$Delay_new == 1]

texas_1 <- texas_1[,c('Delay_new','Start_Lat','Start_Lng', 'Bump', 'Crossing',
                             'Give_Way', 'Traffic_Calming', 'Junction','Stop',
                             'Traffic_Signal','Weekend', 'Sunrise_Sunset','Precipitation', 'Temperature','WindSpeed', 'Humidity','Pressure')]

texas_1$Delay_new <- factor(texas_1$Delay_new)


split <- sample.split(texas_2_3_Var$Delay_new, SplitRatio = 0.75)

# We can over-sample on Train data and the test data set can be used for validation later
dresstrain <- subset(texas_2_3_Var, split == TRUE)
dresstest <- subset(texas_2_3_Var, split == FALSE)

as.data.frame(table(dresstrain$Delay_new))
as.data.frame(table(dresstest$Delay_new))

# Re Sampling, Creating balanced dataset
##------ This would take 40-45 minutes to run ---------
# balanced.data <- SMOTE(Delay_new ~., dresstrain, perc.over=300, perc.under=100, k=5, learner=NULL)
# write.csv(balanced.data,'SMOTE_balanced_data.csv')

balanced.data <- data.table(fread("SMOTE_balanced_data.csv"))
balanced.data <- balanced.data[,-c("V1")]

#combine the datasets
texas_new <- rbind(texas_1, balanced.data, dresstest)

# Severity 1,2 and 3 after Re-sampling 
summary(texas_new$Delay_new)

Table.dat <- data.frame("Delay Levels"= c("1","2", "3"),
           "Before Over Sampling"= c(124759,45622,67112),
           "After Over Sampling"= c(124759,119426,148270))

knitr::kable(Table.dat,caption = " *Number of Observations before and after SMOTE* ", digits = 2)
```

$~$

After performing SMOTE, the number of observations for traffic delay level 2 and 3 has increased as seen from table 4. The test/validation dataset is kept untainted.

$~$

```{r ordinal reg model with oversample, echo = FALSE, warning = FALSE, message= FALSE}

texas_new$Delay_new <- factor(texas_new$Delay_new)
summary(texas_new$Delay_new)

# Training data
polr.LR.ord.resamp <- polr(Delay_new ~ Start_Lat + Start_Lng + Crossing + Give_Way + Junction + 
                     Stop + Traffic_Signal + Sunrise_Sunset +
                   Precipitation + Temperature + WindSpeed + Humidity + Pressure,
                   data = texas_new, Hess = T)

summary(polr.LR.ord)

# Test data
polr.LR.ord.resamp.pred <- predict(polr.LR.ord.resamp, test.data, type = "class")

# Confusion matrix
confusionMatrix(polr.LR.ord.resamp.pred, test.data$Delay_new)


```

$~$

Even with oversampling and even distribution of observations across categories, the overall performance of the model was not improved significantly.  When compared to the previous ordinal logistic model, there is an improvement in predicting delay level 2 observations. The overall accuracy has plummeted to 39%, which is not acceptable.

$~$

$~$

Since Traffic_Dur_min was the key variable to recategorize the traffic delay levels, the distribution of Traffic_Dur_min was closely looked at.


```{r Traffic_Dur_min hist, echo = FALSE, warning = FALSE, fig.height=3, message= FALSE, fig.cap= " *Distribution of traffic duration in minutes* "}

ggplot(data=texas, aes(x = Traffic_Dur_min)) + 
  geom_histogram(fill = "royalblue3") +
  theme (panel.background = element_blank())
  

```

$~$

Since the histogram is bi-modal, it was realized that a binary classification model might be a better fit for this dataset. 


\newpage

## Binary classificication

The Traffic_Dur_min variable has a median of 30min and the mean around 45min. Hence, two scenarios were considered for the preliminary analysis. In the first scenario, accidents with Traffic_Dur_min less than 30min were classified as traffic delay level 1 and more than 30min as traffic delay level 2. In the second scenario, a 45min split was applied to reclassify records as traffic delay levels 1 and 2.

After the accuracy, sensitivity and the specificity obtained by the binary logistic model of 45min split was better when compared to 30min split of delay level classification(Summary of 30 min split model can be referred in the appendix 4). Therefore, 45min split re-classification was considered for this analysis.

The following algorithms have been considered for the binary classification:

* Binary logistic regression

* Discriminant Analysis

* Decision Tree

* K-Nearest Neighbors

* Random Forest

$~$

```{r reclassifying delay levels with 45min split, echo = FALSE, warning = FALSE, message= FALSE}

# reclassification of delay levels
texas$Delay_new <- as.numeric(texas$Delay_new)
texas$Delay_new[texas$Traffic_Dur_min <= 45] <- 1
texas$Delay_new[texas$Traffic_Dur_min > 45] <- 2

texas$Delay_new <- as.factor(texas$Delay_new)

# training and test data
Predictors1 <- texas[,c("V1", "Start_Lat", "Start_Lng", "ST", "Bump", "Crossing", "Give_Way", "Junction",  
                   "No_Exit" , "Railway" , "Roundabout" , "Station" , "Stop" , "Traffic_Calming" , "Traffic_Signal",
                   "Sunrise_Sunset" , "Day" , "Weather_New" , "Precipitation" , "Temperature" , "WindSpeed" ,
                   "Humidity" , "Pressure" , "STHR" , "Weekend", "Delay_new")]


set.seed(42)
train.data <- Predictors1 %>% group_by(Delay_new) %>% sample_frac(0.8)
test.data <- anti_join(Predictors1, train.data, by = "V1")

train.data$Delay_new <- as.factor(train.data$Delay_new)
test.data$Delay_new <- as.factor(test.data$Delay_new)

```

$~$ 

### Binary logistic regression

The binary logistic regression is the most basic algorithm for a classification problem. For all the following algorithms, 45min traffic delay level classification is considered. This model is also used to test the hypothesis that Temperature, Humidity, and Precipitation are significant predictors of traffic delay level.

$~$

```{r binary model with 45min split, echo = FALSE, warning = FALSE, message= FALSE}

Lr <- glm(Delay_new ~ Start_Lat + Start_Lng + Crossing + Give_Way + Junction + Railway + Roundabout + Station + Stop
          + Traffic_Signal + Sunrise_Sunset + Weather_New + Precipitation + Temperature + WindSpeed + Humidity +
            Pressure + STHR + Weekend, data = train.data, family = "binomial")

summary(Lr)

Lr_pred <- predict(Lr, test.data, type = "response")

#confusion matrix
confusionMatrix(as.factor(ifelse(Lr_pred >= 0.5, 2, 1)), test.data$Delay_new, positive = "2")
```

$~$

The associated p-value for Temperature, Humidity, and Precipitation is less than the significance level of 0.05. Thus, we reject the null hypothesis that these variables have no effect on Traffic delay level. There is enough evidence to conclude that with 95% confidence, Temperature, Humidity, and Precipitation are significant predictors of traffic delay level.

As seen in the exploratory data analysis, weekend(weekend and weekday), weather, STHR (Time of day), and Start_Lat & Start_Lng (denoting the location of the accident) variables are also significant predictors of delay level. 


The traffic delay level 2 (impact to clear traffic more than 45min) is considered as the class of interest. Therefore, various probability threshold levels were considered for delay level 2 (refer to appendix 5). After considering sensitivity and specificity, along with accuracy, a probability threshold of 0.25 was considered.

$~$


```{r binary model 0.25 threshold, echo = FALSE, warning = FALSE, message= FALSE}

confusionMatrix(as.factor(ifelse(Lr_pred >= 0.25, 2, 1)), test.data$Delay_new, positive = "2")
```

$~$

After applying a threshold of 0.25, as seen from the confusion matrix, more number of observations are classified as delay level 2 correctly. There is also an increase in the Sensitivity from 21%(threshold of 0.5) to 76% and a decrease in Specificity from 95% to 60%.

$~$

```{r lift chart for 45min split, echo = FALSE, warning = FALSE, message= FALSE, fig.width= 5, fig.height = 3.5, fig.cap= " *Lift chart with the logistic model* "}

test.lvl <- as.numeric(levels(test.data$Delay_new))[test.data$Delay_new]

gain <- gains(test.lvl, Lr_pred, groups = 10)

# Plot Lift Chart
plot(c(0,gain$cume.pct.of.total*sum(as.numeric(test.data$Delay_new))) ~ c(0,gain$cume.obs), 
     xlab = "# cases", ylab = "Cumulative", 
     col = "royalblue3",
     type = "l")
lines(c(0,sum(as.numeric(test.data$Delay_new)))~c(0, dim(test.data)[1]), col = "deepskyblue", lty = 5)

```
$~$

The lift chart shows that the model has gained a lift compared to the base model. In the first 20,000 cases, the model can cumulatively identify nearly 6,000 more traffic delay level 2 cases compared to benchmark model.

$~$

```{r decile chart for 45min split, echo = FALSE, warning = FALSE, message= FALSE, fig.width = 5, fig.cap= " *Decile - Lift chart with the logistic model* "}

### Decile chart
heights <- gain$mean.resp/mean(as.numeric(test.data$Delay_new))
midpoints <- barplot(heights, names.arg = gain$depth,  ylim = c(0,1.7), col = "royalblue3",  border = NA, 
                     xlab = "Percentile", ylab = "Mean Response")

```

The model is likely to identify a delay level 2 accidents in the first 3 deciles (30%) of the decile chart, when the observations are ranked by their propensities. Model can perform nearly 1.22X times better on average in the top three deciles than the random classification model. Since the decile chart is exhibiting better staircase decile, it can be understood that the model is performing it’s best standard.


\newpage

### Discriminant Analysis

The discriminant analysis was considered as it is a model-based approach to classification. The output of a discriminant analysis procedure generates estimated “classification functions,” which are translated into classifications or propensities.

$~$

```{r LDA 45min split, echo = FALSE, warning = FALSE, message= FALSE}

# Train data
lda <- lda(Delay_new ~ Start_Lat + Start_Lng + Crossing + Give_Way + Junction + Railway + Roundabout + Station 
               + Stop + Traffic_Signal + Sunrise_Sunset +  Weather_New + Precipitation + Temperature + WindSpeed +
                 Humidity + Pressure + STHR + Weekend, data = train.data)

# Test data
lda_pred <- predict(lda, test.data)


#confusion matrix
confusionMatrix(lda_pred$class, test.data$Delay_new , positive = "2")

```

$~$

Sensitivity is only 0.18393 and Specificity is 0.96251 with an Accuracy of 74.25% considering the class of interest as ‘delay level 2’. This cutoff threshold needs to be reduced to increase sensitivity.

$~$

```{r lda 0.25 threshold, echo = FALSE, warning = FALSE, message= FALSE}

confusionMatrix(as.factor(ifelse(lda_pred$posterior[,2] >= 0.25, 2, 1)), test.data$Delay_new, positive = "2")

```
$~$

After applying a threshold of 0.25, there is also an increase in the Sensitivity from 18% to 73%. The accuracy of this model is 66%.
 
$~$


```{r LDA plots train, echo = FALSE, warning = FALSE, message= FALSE,  fig.cap= " *LDA plots for train data* "}

lda_pred.train <- predict(lda, train.data)

ldahist(lda_pred.train$x[ ,1], g = train.data$Delay_new,
        xlim = c(-7,7), ymax = 0.8, col = "royalblue3")

```

```{r LDA plots test, echo = FALSE, warning = FALSE, message= FALSE, fig.cap= " *LDA plots for test data* "}

ldahist(lda_pred$x[ ,1], g = test.data$Delay_new,
        xlim = c(-7,7), ymax = 0.8, col = "deepskyblue")

```

Precipitation, Roundabout, and pressure LD scores(refer appendix 6) have the highest impact on the separation line.

In both the LDA plots of training and validation data, the score of less than 0 are mostly classified as traffic delay level 1, and score greater than 0 are mostly classified as traffic delay level 2. Though there are some misclassifications, scores hold true for the majority of the observations. The LDA has created separation among the two classes.


\newpage

### Decision Tree

Decision tree is a graph to represent choices and their results in form of a tree. The nodes in the graph represent an event or choice and the edges of the graph represent the decision rules or conditions. Decision tree works on both classification and regression problems and also works on both categorical and continuous input output variable.

$~$

```{r rpart with 45min split, echo = FALSE, warning = FALSE, message= FALSE}

options(scipen = 999)

control <- rpart.control(minbucket = 2000, cp = 0.007, maxsurrogate = 0, usesurrogate = 0, xval = 10)

rpart <- rpart(Delay_new ~ Start_Lat + Start_Lng + Crossing + Give_Way + Junction + Railway + Roundabout + Station 
               + Stop + Traffic_Signal + Sunrise_Sunset +  Weather_New + Precipitation + Temperature + WindSpeed +
                 Humidity + Pressure + STHR + Weekend, data = train.data, method = "class",
               control = control)

tree <- prp(rpart, type = 1, extra = 1, under = TRUE, roundint = FALSE, 
            split.font = 4, varlen = -10, box.palette = "BuOr")

rpart.rules(rpart, cover = TRUE)


model.pred.train <- predict(rpart,  data = train.data, 
                            type = "class")


# for Validation set
model.pred.test <- predict(rpart, newdata = test.data, 
                           type = "class")

confusionMatrix(model.pred.test, as.factor(test.data$Delay_new), positive = "2")

```

$~$

Decision tree is performing better compared to the binary logistic regression model used above. This model has accuracy of 0.72 and sensitivity and specificity of 0.79 and 0.65 respectively. 


\newpage

### K-Nearest Neighbours (KNN)

This supervised machine learning algorithm was considered to classify and predict traffic delay levels. The method relies on finding “similar” records in the training data. These “neighbors” are then used to derive a classification or prediction for the new record.

$~$

```{r KNN 45min split, echo = FALSE, warning = FALSE, message= FALSE}

##extract 26th column of test dataset to measure the accuracy
Delay_category_train <- train.data[,26,drop = T]
Delay_category_test <- test.data[,26, drop = T]


train_knn = train.data[,c('Delay_new','Start_Lat','Start_Lng','Crossing','Give_Way','Junction',
                          'Railway','Roundabout','Station', 'Stop', 'Traffic_Signal', 'Sunrise_Sunset',
                          'Precipitation','Pressure','Temperature','WindSpeed', 'Humidity', 'Weekend')]


test_knn = test.data[,c('Delay_new','Start_Lat','Start_Lng','Crossing','Give_Way','Junction',
                        'Railway','Roundabout','Station', 'Stop', 'Traffic_Signal', 'Sunrise_Sunset',
                        'Precipitation','Pressure','Temperature' ,'WindSpeed', 'Humidity', 'Weekend')]


train_knn <- as.data.frame(train_knn)
test_knn <- as.data.frame(test_knn)

# coverting factors into numeric for KNN
train_knn$Sunrise_Sunset <- as.numeric(train_knn$Sunrise_Sunset)
train_knn$Weekend <- as.numeric(train_knn$Weekend)

test_knn$Sunrise_Sunset <- as.numeric(test_knn$Sunrise_Sunset)
test_knn$Weekend <- as.numeric(test_knn$Weekend)


# KNN model
knn <- knn(train = train_knn, test = test_knn, cl=as.vector(Delay_category_train),
           k=5, prob = T)

# Confision matrix
confusionMatrix(knn, Delay_category_test$Delay_new, positive = "2" )

```


$~$

The KNN model has a sensitivity of 72% and an accuracy of 90%. Since the training dataset is large, and each class is characterized by multiple combinations of predictor values, this KNN model has performed well. The time required to run this algorithm might be more when compared to other models as it computes distances from the entire set of training records only at the time of prediction. 


\newpage

### Random Forest

In the random forest approach, a large number of decision trees are created. Every observation is fed into every decision tree. The most common outcome for each observation is used as the final output. In classification, it uses the majority vote of the outcome variable and in the regression model, it considers the average of the output variable.

```{r Random forest 45min split, echo = FALSE, warning = FALSE, message= FALSE}

rf <- randomForest(Delay_new ~ Start_Lat + Start_Lng + Crossing + Give_Way + Junction + Railway + Roundabout +
                     Station + Stop + Traffic_Signal + Sunrise_Sunset + Day + Weather_New + Precipitation +
                     Temperature + WindSpeed + Humidity + Pressure + STHR + Weekend,
                   data = train.data, mtry = 8, importance = T)

# predict
rf.test <- predict(rf, test.data)

# confusion matrix
confusionMatrix(rf.test, test.data$Delay_new, positive = "2")
```

 $~$
 
The Random Forest model has a sensitivity of 69% and an accuracy of 83%. The run time for this model is more as it decorrelates several trees which are generated on the different bootstrapped samples from the training Data and then averages the trees and reduces the Variance and avoids Over fit in Trees.



\newpage

# Conclusions

$~$

It is more important to correctly identify the accidents that have a tremendous impact on traffic time. With delay level 2 (high impact on traffic) as the class of interest, Sensitivity, specificity, and accuracy of all the models were compared. The results are summarized in table 5.

**KNN** is considered as the **best model** with 72% sensitivity, 96% specificity, and 89.7% accuracy. The variables considered are Start_Lat, Start_Lng, Crossing, Give_Way, Junction, Railway, Roundabout, Station, Stop, Traffic_Signal’, Day_Night, Precipitation, Pressure, Temperature, WindSpeed, Humidity, Weekend. A conscious effort has been made in building a model with the input variables, whose data will be available when an accident is reported at TMC. 


If two accidents are reported at a given point in time, Transportation Management Center (TMC) can allot its resources based on the traffic delay levels. Thus, there is a need to identify both delay level 1 and delay level 2 accidents correctly i.e; a model with both high sensitivity and specificity along with accuracy.
In case of high delay level, Emergency Medical Services can take a call on the requirement of airlift instead of an ambulance by road to save a life.

Different versions of this model can be created for each city level TMC for better prediction. This type of prediction model can help reduce traffic delay time and in turn, reducing the congestion costs, including travel delay and excess fuel consumption.

$~$

```{r conclusion, echo = FALSE, warning = FALSE, message= FALSE}

conclusion <- data.frame("Classifier"= c("Binary logistic regression","Discriminant Analysis","Decision Tree","K-Nearest Neighbors", "Random Forest"),
           "Sensitivity"=c(0.76,0.74,0.79,0.72,0.69),
           "Specificity"=c(0.60,0.63,0.65,0.96,0.89),
           "Accuracy"= c("64.48%","66.26%","71.79%","89.77%","83.24%"))

conclusion <- as.data.table(conclusion)

knitr::kable(conclusion,
             caption = "Summary of all the Algorithms")

```









\newpage

# References

Blincoe, L., Miller, T. R., Zaloshnja, E., & Lawrence, B. A. (2015). *The Economic and Societal Impact of Motor Vehicle Crashes, 2010 (Revised)*. Washington, DC: National Highway Traffic Safety Administration.

Cools, M., Moons, E., & Wets, G. (2009). Assessing the Impact of Weather on Traffic Intensity. *Weather, Climate and Society*, 2, 60-68.

Head, A. J. (1959). Predicting traffic accidents from roadway elements on urban extensions of state highways. *Highway Research Board Bulletin, 208*, 45-63. National Research Council (USA), Highway Research Board.

KRW Attorneys at Law. (n.d.). *Texas Car Accident Statistics*. Retrieved 11 03, 2020, from KRW Attorneys at Law: https://www.krwlawyers.com/san-antonio-personal-injury-lawyer/automotive-accidents/car-accidents/texas-car-accident-statistics/

Martin, J.-L. (2002). Relationship between crash rate and hourly traffic flow on interurban motorways. *Accident Analysis & Prevention, 34(5)*, 619-629.

National Center for Statistics and Analysis. (2020, May). Early Estimate of Motor Vehicle Traffic Fatalities in 2019. *Traffic Safety Facts(DOT HS 812 946)*. National Highway Traffic Safety Administration.

Pisano, P. A., Goodwin, L. C., & Rossetti, M. A. (2008). U.S. highway crashes in adverse road weather conditions. 24th Conference on IIPS.

Retallack, A. E., & Ostendorf, B. (2019, September). Current Understanding of the Effects of Congestion on Traffic Accidents. *Int J Environ Res Public Health*.

U.S. Department of Transportation. (2017, February 1). *Regional Concept for Transportation Operations*. Retrieved September 07, 2020, from Federal Highway Administration: https://ops.fhwa.dot.gov/publications/rctoprimer/prim0701.htm

Wagner, I. (2020, July 24). *Road accidents in the United States - Statistics & Facts*. Retrieved September 07, 2020, from Statista: https://www.statista.com/topics/3708/road-accidents-in-the-us/

Wallace, C. E. (n.d.). *ITS Professional Capacity Building Program*. Retrieved September 7, 2020, from United States Department of Transportation: https://www.pcb.its.dot.gov/eprimer/module4.aspx#fn4

Woo, J. C. (1957). Correlation of Accident Rates and Roadway Factors. Purdue University.

Zhou, M., & Sisiopiku, V. P. (1997). Relationship between volume-to-capacity ratios and accident rates. *Transportation research record*, 1581, 47-52.

**Dataset Acknowledgments:**
Moosavi, Sobhan, Mohammad Hossein Samavatian, Srinivasan Parthasarathy, and Rajiv Ramnath. *“A Countrywide Traffic Accident Dataset.”*, arXiv preprint arXiv:1906.05409 (2019).

Moosavi, Sobhan, Mohammad Hossein Samavatian, Srinivasan Parthasarathy, Radu Teodorescu, and Rajiv Ramnath. *“Accident Risk Prediction based on Heterogeneous Sparse Data: New Dataset and Insights.”* In proceedings of the 27th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, ACM, 2019


\newpage

# Appendices

## *Appendix 1: Description of variables in US Accidents data set*
```{r Appendix 1, echo = FALSE, warning = FALSE, message= FALSE}

Var.Des <- data.table(read.csv("Variable description.csv"))

knitr::kable(Var.Des, "latex") 

```

\newpage

## *Appendix 2: Summary of Stepwise regression for variable selection*

$~$

```{r Appendix 2, echo = FALSE, warning = FALSE, message= FALSE}

with(reg.summary, data.frame(adjr2, outmat))

best.step <- which.max(reg.summary$adjr2)

```


\newpage

## *Appendix 3: Multinomial logistic regression (3 class classification)*

$~$

```{r MLR, echo = FALSE, warning = FALSE, message= FALSE}

multinom_LR <- multinom(Delay_new ~ Start_Lat + Start_Lng + Crossing + Give_Way + Junction + Railway + Roundabout + Station + Stop
          + Traffic_Signal + Sunrise_Sunset + Weather_New + Precipitation + Temperature + WindSpeed + Humidity +
            Pressure + STHR + Weekend, data = train.data)

summary(multinom_LR)

multinom_LR_pred <- predict(multinom_LR, test.data, type = "class")

confusionMatrix(multinom_LR_pred, test.data$Delay_new)

```


\newpage

## *Appendix 4: Logistic regression with 30min reclassification split*

$~$

```{r reclassifying delay levels with 30min split, echo = FALSE, warning = FALSE, message= FALSE}

texas$Delay_new <- as.numeric(texas$Delay_new)
  
texas$Delay_new[texas$Traffic_Dur_min <= 30] <- 1
texas$Delay_new[texas$Traffic_Dur_min > 30] <- 2

texas$Delay_new <- as.factor(texas$Delay_new)

set.seed(42)
train.data <- texas %>% group_by(Delay_new) %>% sample_frac(.8)
test.data <- anti_join(texas, train.data, by = "V1")

```


```{r binary model with 30min split, echo = FALSE, warning = FALSE, message= FALSE}

Lr <- glm(Delay_new ~ Start_Lat + Start_Lng + Crossing + Give_Way + Junction + Railway + Roundabout + Station + Stop
          + Traffic_Signal + Sunrise_Sunset + Weather_New + Precipitation + Temperature + WindSpeed + Humidity +
            Pressure + STHR + Weekend, data = train.data, family = "binomial")

summary(Lr)

Lr_pred <- predict(Lr, test.data, type = "response")

#confusion matrix
confusionMatrix(as.factor(ifelse(Lr_pred >= 0.25, 2, 1)), test.data$Delay_new, positive = "2")

```


```{r rpart with 30min split, echo = FALSE, warning = FALSE, message= FALSE}

control <- rpart.control(minbucket = 2000, cp = 0.007, maxsurrogate = 0, usesurrogate = 0, xval = 10)

rpart <- rpart(Delay_new ~ Start_Lat + Start_Lng + Crossing + Give_Way + Junction + Railway + Roundabout + Station 
               + Stop + Traffic_Signal + Sunrise_Sunset +  Weather_New + Precipitation + Temperature + WindSpeed +
                 Humidity + Pressure + STHR + Weekend, data = train.data, method = "class",
               control = control)

tree <- prp(rpart, type = 1, extra = 1, under = TRUE, roundint = FALSE, 
            split.font = 4, varlen = -10, box.palette = "BuOr")

rpart.rules(rpart, cover = TRUE)


model.pred.train <- predict(rpart,  data = train.data, 
                            type = "class")


# for Validation set
model.pred.test <- predict(rpart, newdata = test.data, 
                           type = "class")

confusionMatrix(model.pred.test, as.factor(test.data$Delay_new), positive = "2")

```



\newpage

## *Appendix 5: Various Cut off levels for Binary Logistic regression *

$~$

Cutoff level 0.15
```{r logistic regression1, echo = FALSE, warning = FALSE, message= FALSE}

confusionMatrix(as.factor(ifelse(Lr_pred >= 0.15, 2, 1)), test.data$Delay_new, positive = "2")

```

Cutoff level 0.20
```{r logistic regression2, echo = FALSE, warning = FALSE, message= FALSE}

confusionMatrix(as.factor(ifelse(Lr_pred >= 0.2, 2, 1)), test.data$Delay_new, positive = "2")

```

Cutoff level 0.35
```{r logistic regression3, echo = FALSE, warning = FALSE, message= FALSE}

confusionMatrix(as.factor(ifelse(Lr_pred >= 0.35, 2, 1)), test.data$Delay_new, positive = "2")

```

\newpage

## *Appendix 6: Coefficients of Linear Discriminants *

$~$

```{r coeff LDA, echo = FALSE, warning = FALSE, message= FALSE}

lda$scaling

```

The coefficient of linear discriminants gives us the weightage of each of the variable. The LD’s formed here are used to create a separation line between the classes (delay level 1 and 2).

The coefficients of linear discriminants help us to understand the impact of variables on the separation line. The higher weight variables have more impact. They contribute to the transformation of original data set into a common scale. The coefficient are multipied by the actual variables to get the linear discriminant scores.

In this case, the separation line formula would be given by,
Y = -0.12566 (Start_Lat) + 0.18848 (Start_Lng) - 0.01434 (crossing) .. . . . .. -0.17936 (Weekend)

Y = Coeff of LD1 * Variable 1


\newpage

## *Appendix 7: Various Cut off levels for LDA *

$~$

Cutoff level 0.15
```{r LDA1, echo = FALSE, warning = FALSE, message= FALSE}

confusionMatrix(as.factor(ifelse(lda_pred$posterior[,2] >= 0.15, 2, 1)), test.data$Delay_new, positive = "2")

```

Cutoff level 0.22
```{r LDA2, echo = FALSE, warning = FALSE, message= FALSE}

confusionMatrix(as.factor(ifelse(lda_pred$posterior[,2] >= 0.22, 2, 1)), test.data$Delay_new, positive = "2")

```

Cutoff level 0.30
```{r LDA3, echo = FALSE, warning = FALSE, message= FALSE}

confusionMatrix(as.factor(ifelse(lda_pred$posterior[,2] >= 0.3, 2, 1)), test.data$Delay_new, positive = "2")

```

